version: '3.8'

services:
  ai-town:
    image: ai-town-ai-town:latest
    container_name: ai-town-production
    ports:
      - "5173:5173"      # Vite 前端
      - "3210:3210"      # Convex 本地後端 WebSocket
    volumes:
      # 只掛載資料庫,不覆蓋應用程式碼
      # 映像已包含所有必要檔案
      - ai-town-database:/usr/src/app/database
      # 掛載 .env.example 讓容器內部創建 .env.local
      - ./.env.local:/usr/src/app/.env.example:ro
    environment:
      - NODE_ENV=production
      - VITE_CONVEX_URL=http://127.0.0.1:3210
      # 添加 Ollama URL 環境變量
      - LLM_API_URL=http://host.docker.internal:11434
    networks:
      - ai-town-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5173"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    extra_hosts:
      - "host.docker.internal:host-gateway"  # 添加這一行以確保網絡訪問

volumes:
  ai-town-database:

networks:
  ai-town-network:
    driver: bridge
